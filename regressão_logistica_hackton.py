# -*- coding: utf-8 -*-
"""regressão logistica hackton.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xnPs-jad21GJHDMHMCmvaCBgVlChMaI5
"""

#Instalaçao das ferramentas

pip install pandas scikit-learn

#Importação

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, matthews_corrcoef, cohen_kappa_score

#Ingestão da base de treinamento/teste

treino = pd.read_csv('Inserir o caminho da base .csv separado em ;', sep=';')

treino.head()

X = treino.drop('PROCESSO', axis=1)
y = treino['PROCESSO']

#Separação aleatoria dos dados para treino e teste do modelo

X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)

#Transformaçao dos dados para a adequação da biblioteca de regressão

scaler = StandardScaler()
X_treino = scaler.fit_transform(X_treino)
X_teste = scaler.transform(X_teste)

#Criação do modelo e treinamento

regressao = LogisticRegression()

regressao.fit(X_treino, y_treino)

res = regressao.predict(X_teste)

#Verificação dos parametros dos modelos e acuracia

accuracy = accuracy_score(y_teste, res)
print(f"Acurácia: {accuracy:.2f}")

report = classification_report(y_teste, res)
print("Relatório de Classificação:\n", report)

precision = precision_score(y_teste, res) #Evitar falso positivo
recall = recall_score(y_teste, res) #Encontrar verdadeiro positivo - Preciso de um recall baixo, pois falso positivo é caro
f1 = f1_score(y_teste, res)

print(f"Precisão: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-score: {f1:.2f}")

conf_matrix = confusion_matrix(y_teste, res)
print("Matriz de Confusão:\n", conf_matrix)

#Verificaçao da importancia de cada parametro para o modelo

coefficients = regressao.coef_[0]
feature_names = X.columns
coefficients_df = pd.DataFrame({'Variável': feature_names, 'Coeficiente': coefficients})
coefficients_df['Abs. Coeficiente'] = np.abs(coefficients_df['Coeficiente'])
coefficients_df = coefficients_df.sort_values(by='Abs. Coeficiente', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(coefficients_df['Variável'], coefficients_df['Coeficiente'])
plt.xlabel('Coeficiente')
plt.title('Importância das Variáveis no Modelo de Regressão Logística')
plt.show()

#Ingestão da base para os casos reais

real = pd.read_csv('Inserir o caminho da base .csv separado em ;', sep=';')

real.head()

scaler = StandardScaler()
real_trans = scaler.fit_transform(real)

#Predição da base

resultado = regressao.predict(real_trans)

resultado_df = pd.DataFrame({'previsao': resultado})

export_df = pd.concat([real, resultado_df], axis=1)
export_df.head()

#Export dos resultados

export_df.to_csv('Inserir o caminho para a geração do resultado', index=True, sep=';')